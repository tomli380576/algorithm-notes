[[{"l":"Algorithm Notes","p":["My notes for 122A, 122B and more."]}],[{"l":"Dp intro"}],[{"i":"rod-cutting-122a","l":"Rod Cutting (122A)","p":["Question. Given a rod with length n and an array of prices of each length p_i, how can we cut the rod to make the most amount of money?","We are given the following:","n: int, length of the rod","p: Arrayint, array of prices for rod length from i=1 to i=n","For example: p_1 = 1, p_2 = 3, p_3 = 5, \\dots","We want to find:","int, the max revenue possible r from rod of length n","Arrayint, cut strategy to make the max revenue. Element at index i represents the amount to cut at step i.","Let's call this function CutRod(n, p). Since p is fixed, we will omit p from the call signature from now on."]},{"l":"Solve the Backtracking Problem"},{"l":"Base Cases","p":["Recall from basic recursion that the bases cases are the subproblems that we can immediately solve. We know how to solve:","n = 0, we have no rod, so we make no money.","n = 1, we have the shortest rod that we can possibly sell, so the profit is exactly p_1"]},{"l":"Recursive Cases","p":["We first consider what a choice is and how to make a choice.","A choice is the length we can cut from the current rod.","So the set of choices is from 1 to n because they are all valid. To make a choice, we decrease the rod length by our chosen length and add that price to the current total price.","We also want to take the best choice, so we need a max call:","From the all the possible cuts, take the one that gives the maximum profit"]},{"l":"The Recurrence","p":["This problem falls under the best solution case because we want the maximum amount of money.","Translate it into expressions:"]},{"l":"Backtracking Implementation","p":["In short, the components of this recursive backtracking problem are:","Sequence of decisions- We need to make a sequence of cuts.","Make 1 decision at a time- We make 1 cut at every recursive call.","A choice here is the length to cut. All lengths from 1 to the remaining length is valid","To make a choice, decrease the remaining length.","Satisfy all the constraints- We can’t cut more rod than we currently have.","Make sure you are comfortable with the brute force approach before moving to DP conversion."]},{"l":"Convert to Dynamic Programming"},{"l":"Data structure","p":["Observe that every call requires only 1 argument rodLen, so we can use an 1D array to store our results. Let’s define:","To get the result of a previous call, we can use dpTable[rodLen].","This dpTable[rodLen] corresponds to the brute force result CutRod(rodLen).","If you really wish to make this pretty, name the DP table cutRod.","The final result should be in dpTable[maxRodLen] where maxRodLen is the initial parameter (represents the full rod length)"]},{"l":"Order of evaluation","p":["The function depends on other recursive calls in this way:","Equivalently from the recurrence:","So we need to evaluate all of \\{\\text{CutRod}(n-i)\\}_{1\\leqslant i \\leqslant n} first before we can know the result of CutRod(n). Since n-i < n, the first thing that goes into the table is CutRod(0) and we evaluate in ascending order."]},{"l":"Build the DP Table"},{"l":"Reconstructing the Solution","p":["The pseudocode above only finds the optimal profit, but it doesn't tell us how to actually cut the rod. We can record the cut by adding the following"]},{"l":"DP Implementation"},{"l":"Runtime Analysis","p":["We can see that this is the classic nested for loop:","So the runtime is O(n^2) and memory is O(n) from 1D Array."]},{"l":"Proof. Optimal Substructure","p":["State the given:","Given \\text{OPT}(n) for rod of length n with first cut i","\\text{OPT}(n)=p_i + a, where a is the amount of money made on rod of length n-i","Prove: a is the optimal solution for rod of length n-i, or a = \\text{OPT}(n-i)","Assume a is not optimal for rod of length n-i","Let rev(t) denote the revenue from strategy t","Then there exists another strategy b such that rev(b)>rev(a)","We already assumed OPT is the best solution, then a better one cannot exist.","Contradiction with given. Therefore a is optimal for n-i.","The key point is that the optimal solution to the subproblem is unique."]}],[{"l":"The Only Graph Traversal Algorithm"},{"l":"Whatever First Search","p":["Question. How to visit every vertex exactly once in a graph?","To keep track of which vertices we have seen, we use 2 \\texttt{STATUS} values:","\\texttt{NEW}: Never seen before.","\\texttt{VISITED}: Processed exactly once.","Let T be the generic typename. We will make up an imaginary data structure called a BagT. It has 3 methods:","put(elem: T) puts an element in the bag.","popFirst() - T returns whatever is the \"first\" thing in the bag and removes it.","isEmpty() - bool returns whether the bag is empty or not.","Then the pseudocode for whatever first search is:","Here process(u) is just a blackbox subroutine. We can do anything inside process(u) as long as we don’t change the vertex status."]},{"l":"Important Variants","p":["By changing the bag's behavior of popFirst(), we get the familiar search algorithms:","Depth First Search. DFS is usually implemented with recursion allowing cycle detection.","Breadth First Search","Best First Search"]},{"l":"Python","p":["The WhateverFirstSearch_Connected function implements this.","This version of Whatever First Search assumes that the start can actually reach every other vertex in the graph. This works if we know the graph is connected.","To handle disconnected graphs we need to make the following modifications."]},{"i":"whatever-first-searchall","l":"Whatever First Search–All","p":["For each vertex in G, if we’ve never visited this vertex before, visit everything that we can reach from this vertex.","We will make a small wrapper.","Changing the bag's behavior on popFirst() will result in the same variants, but now they can handle disconnected graphs."]},{"l":"Python","p":["The WhateverFirstSearch_All function implements this.","Go to next:","BFS & DFS"]}],[{"i":"breadth-first-search-122a","l":"Breadth First Search (122A)"},{"l":"Basics","p":["We can implement BFS from whatever first search by using a Queue.","The 122A version checks whether the adjacent vertex v is visited. The WFS version checks if the current vertex u is new."]},{"l":"Python"},{"i":"with-time-full-122a-version","l":"With time (full 122A Version)","p":["We can also record \"when\" a vertex is visited. Each time we see a new vertex, we increment the \"time\". The discover time of a vertex starts with \\infin."]},{"i":"observing-bfss-behavior","l":"Observing BFS’s Behavior","p":["We can observe how each ‘layer’ of the graph is being visited by BFS by adding a special token.","The changes are highlighted. Everything else is the same.","while queue has at least 1 vertex does not mean queue.size 0. The special token is not a vertex."]},{"l":"Python"},{"l":"Examples"},{"i":"ex1","l":"EX.1","p":["Given this graph, and we start at vertex \\tt{S}","Starting from \\tt S, we can see that all the red nodes \\tt{\\red{ACG}} are 1 edge away, and the purple nodes \\tt\\purple{BDEFH} are 2 edges away."]},{"i":"ex2","l":"EX.2","p":["If we start at \\tt{\\color{darkorange}A}, then the graph will be visited in this order: \\tt{{\\color{darkorange} A}\\to \\red {BCE}\\to\\purple D}","Vertices with the same color could be visited in any order depending on the order of insertion, but the overall order is Orange → Red → Purple.","Running the code from 2.3:"]}],[{"i":"recursive-depth-first-search-122a","l":"Recursive Depth First Search (122A)"},{"l":"1. Vertex Status","p":["Similar to whatever first search, we assign each vertex a \\purple{\\texttt{STATUS}}.","\\texttt{NEW}: literally never seen before, all vertices start with this status","\\texttt{ACTIVE}: seen before, but the adjacent vertices are not done processing yet","\\texttt{FINISHED}: the vertex is seen and all its children are done processing"]},{"l":"2. Pseudocode"},{"l":"Barebones Version"},{"i":"with-clock-122a","l":"With Clock (122A)","p":["Long Version"]},{"l":"Comparison with stack based Whatever First Search","p":["The recursive version replaces stack.put(v) with the recursive call DFS_Visit(v).","while stack is not empty is the same as coming back to the initial call (empty call stack).","Every time DFS_Visit(v) is called in the main routine, a new call stack is initialized. WFS does this by calling the stack constructor."]},{"l":"3. Runtime Analysis","p":["We call the DFS_Visit(v) function V times in the main routine","The total number of recursive calls inside DFS_Visit(v) is E times because we will traverse each edge exactly once. So E times for the entire graph.","The total runtime is O(V+E)"]},{"i":"4-python-basic-dfs","l":"4. Python: Basic DFS","p":["example_unweighted_graphs.py DIRECTED_1","ECS122A-Algorithms-python-implementation/basic-DFS.py at main · tomli380576/ECS122A-Algorithms-python-implementation"]},{"l":"5. Classifying Edges and Cycle Detection","p":["There are 4 possible types of edges:","More specifically:","Source: Prof Bai’s 122A slides. Gray = Active, White = New, Black = Finished"]},{"i":"51-edge-interpretations","l":"5.1 Edge Interpretations","p":["At least one back edge is found \\iff the graph has a cycle","So Directed Acyclic Graphs (Like a DP dependency graph) cannot have a back edge","Found at least 1 cross or forward edge \\implies the graph is directed"]},{"i":"6-python-dfs-with-edge-classification","l":"6. Python: DFS with edge classification","p":["ECS122A-Algorithms-python-implementation/DFS-cycle-detection.py at main · tomli380576/ECS122A-Algorithms-python-implementation","Right now it only finds back and tree edges correctly, still figuring out how to find forward and cross edges","Go back:","\\star Basics of DFS & BFS","Go to next:","Breadth First Search (122A)"]}],[{"i":"max-subarray-122a","l":"Max Subarray (122A)"},{"l":"Problem Statement","p":["Question. Given a 1-dimensional array, find a contiguous sub-array with the largest sum","the array we select from"]},{"l":"Dividing the problem","p":["The maximum subarray can show up in 3 places:","The left half of A","The right half of A","The middle section of A","The left half and right half does not overlap. Overlap is handled by the middle section."]},{"l":"Base Cases","p":["There are 2 base cases:","A is empty, so we return 0 for the sum of nothing.","A has exactly 1 element, so we return that element A[1]"]},{"l":"Recursive Cases","p":["To avoid passing the main array around on the stack, we can use the 2 pointer approach with low and high pointers. The recursive calls will look like:","where the 2 recursive calls correspond to the left and right half of A."]},{"l":"The Max Middle Sum","p":["The name is kinda misleading, but we want to consider this:","Question. What contiguous subarray, that might contain the middle element, gives us the maximum sum?","So we check both ways. Take the element if it keeps the array contiguous AND increases the sum.","Check from mid - 1 to low","**Ex.** Left Half","Then check from mid to high","**Ex.** Right Half","The best middle sum could also involve both the left and right half, for example if all elements are positive.","So we take the max(...) of all:"]},{"l":"Combining the Results","p":["Now we know what’s max in left, right, and middle, we just take the max","We don’t try to combine left and right here because that won’t be contiguous anymore."]},{"l":"Pseudocode"},{"i":"python-max-subarray","l":"Python: Max Subarray","p":["Go faster: ❖ Max Subarray: Kadane’s Algorithm (WIP)"]}],[{"i":"merge-sort-122a","l":"Merge Sort (122A)","p":["Given A: Arrayint, the idea of merge sort is:"]},{"l":"Dividing the Problem","p":["We need to split the array in half. Let low and high denote the current starting and ending indices of the array (inclusive). Then we can find the middle index mid by:","Note that this could cause integer overflow when low and high are large. A better way would be:","And the recursive calls are:"]},{"l":"Base Cases","p":["This is where we actually do the comparison. We have 2 base cases:","The array is empty or has 1 element, then we do nothing.","The array has exactly 2 elements, then we directly compare.","This case could be implicitly handled by merging two 1–element arrays, so no need to explicitly implement this case."]},{"l":"Merge 2 sorted Arrays","p":["Now that the recursion has sorted the left and right array for us, we need to merge them together. We can use the 2 pointer approach here.","Let ptr_l and ptr_r be the traversing pointers in the left & right sorted arrays respectively.","It’s probably easier to consider merging with 2 separate arrays first.","Translate into expressions: (Assuming we are sorting in ascending order. Flip < to > if reversed.)","The 2nd and 3rd while loops are safe because at most 1 of them will run, and the loop that runs corresponds to the array that has all its remaining elements \\geqslant the last element in output.","We can also see that this is a linear scan, so the runtime is O(n)."]},{"l":"Implementation Detail","p":["In actual implementation, don’t actually slice the main array into L and R because passing arrays on the stack is expensive. Instead, pass in an extra parameter mid to indicate where the left half ends, then merge with the same 2 pointer approach.","At the end, instead of returning output, replace all elements in the parameter array with output. This requires the main array to be passed as a reference so it may be different depending on the language."]},{"l":"Code"}],[{"i":"quick-select-122b-wip","l":"Quick Select (122B) (WIP)","p":["Type of Divide & Conquer: Pivot","Required: Quick Sort","@Params","A:\\texttt{\\gray{\\blue{Array}<\\blue{number}>}}, the array we select from","k:\\tt{\\blue{int}}, the k-th smallest number to look for; 1\\le k\\le \\text{len}(A)","@Returns The k-th smallest element of A in linear time.","Question. Given an unsorted list of numbers A and an integer k, how do we find the k-th smallest element of A in O(n) time?"]}],[{"i":"quick-sort-122a","l":"Quick Sort (122A)"},{"l":"Problem Statement","p":["@Params A:\\texttt{\\gray{\\blue{Array}<\\blue{number}>}}, the array to sort","The idea of quick sort is:"]},{"l":"Base Case","p":["When A has 1 or 0 elements, we do nothing."]},{"l":"Partition","p":["↑ This partitioning step is doing most of the work.","Unlike merge sort, after left & right partitions are sorted, the merging step is already done.","Similar to how we considered merge(), it’s easier to think about if we use extra space.","(Change < to other comparators depending on the sorting order)","This is also a linear scan, so the runtime is O(n)."]},{"l":"Choosing the Pivot","p":["There are a lot of ways for choosing pivots:","Always pick first","Always pick last","Choose randomly","Somehow pick out the true median of A(important for quick select)","Source"]},{"l":"Pseudocode"},{"i":"python-quick-sort","l":"Python: Quick Sort"}],[{"i":"randomized-quick-select-122b-wip","l":"Randomized Quick Select (122B) (WIP)","p":["Type of Divide & Conquer: Pivot"]}],[{"i":"tower-of-hanoi-36b","l":"Tower of Hanoi (36B)"},{"l":"Problem Statement","p":["Question. Given 3 pegs and n disks, how can we move all the disks from \\tt{src} to \\tt{dest} such that larger disks cannot stack on top of smaller disks?","number of disks. This implies we have disk from radius 1 to n","3 pegs that we can puts disks on.\\tt{src} initially has the disks [1\\dots n] on it.\\texttt{dest, temp} will be empty initially."]},{"l":"Reducing the problem","p":["Source: Erickson Text","We can observe that:","The largest disk has to go on the \\tt{dest} peg first before everything else.","To do so, we need to move everything else to the \\tt{temp} peg first. Now \\tt{src} only has the largest disk and \\tt{dest} is empty ⇒ so we can directly move.","Let’s consider a simple case with only 2 disks.","We do this 4-step process for any number of disks, except that 2 is the n-th disk and disk 1\\sim n is in the position of 1."]},{"l":"Pseudocode"},{"i":"python-tower-of-hanoi","l":"Python: Tower of Hanoi"}]]